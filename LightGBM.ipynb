{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy as scipy\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train =  pd.read_csv('../input/train.csv', nrows = 29000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows before data cleaning:  29000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Rows before data cleaning: \", train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(how = 'any', axis = 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows where:\n",
    "* Fare Amount is less than 0\n",
    "* Fare Amount is more than $400\n",
    "* Pickup & Dropoff Latitude & Longitude are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[ (train.fare_amount > 0)  & (train.fare_amount <= 300) & (train.pickup_longitude != 0) & (train.pickup_latitude != 0) & (train.dropoff_longitude != 0) & (train.dropoff_latitude != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows after data cleaning:  28419871\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Rows after data cleaning: \", train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define A Function, that calculates Distance using Haversine Distance Formula and calculates Bearing\n",
    "\n",
    "https://en.wikipedia.org/wiki/Haversine_formula\n",
    "https://en.wikipedia.org/wiki/Bearing_(navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def havesine_distance_and_bearing(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude,getBearing):\n",
    "\n",
    "    #Define earth radius (km)\n",
    "    R_earth = 6371\n",
    "    #Convert degrees to radians\n",
    "    pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude = map(np.radians, [pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude])\n",
    "    \n",
    "    #Compute distances along lat, lon dimensions\n",
    "    dlatitude = dropoff_latitude - pickup_latitude\n",
    "    dlongitude = dropoff_longitude - pickup_longitude\n",
    "    \n",
    "    #Compute haversine distance\n",
    "    harversineDistance = np.sin(dlatitude/2.0)**2 + np.cos(pickup_latitude) * np.cos(dropoff_latitude) * np.sin(dlongitude/2.0)**2\n",
    "    \n",
    "    \n",
    "    if getBearing:\n",
    "        #Compute Bearing Distance\n",
    "        bearing = np.arctan2(np.sin(dlongitude * np.cos(dropoff_latitude)),np.cos(pickup_latitude) * np.sin(dropoff_latitude) - np.sin(pickup_latitude) * np.cos(dropoff_latitude) * np.cos(dlongitude))\n",
    "\n",
    "        return 2 * R_earth * np.arcsin(np.sqrt(harversineDistance)), bearing\n",
    "    else:\n",
    "        return 2 * R_earth * np.arcsin(np.sqrt(harversineDistance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Distance From Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_airport_dist(df):\n",
    "    \"\"\"\n",
    "    Return minumum distance from pickup or dropoff coordinates to each airport.\n",
    "    NYC: Newyork Central\n",
    "    SOL: Statue of Liberty \n",
    "    JFK: John F. Kennedy International Airport\n",
    "    LGA: LaGuardia Airport\n",
    "    EWR: Newark Liberty International Airport\n",
    "    \"\"\"\n",
    "    nyc_coord = (40.7141667,-74.0063889) \n",
    "    sol_coord = (40.6892,-74.0445)\n",
    "    jfk_coord = (40.639722, -73.778889)\n",
    "    ewr_coord = (40.6925, -74.168611)\n",
    "    lga_coord = (40.77725, -73.872611)\n",
    "    \n",
    "    \n",
    "    pickup_lat = df['pickup_latitude']\n",
    "    dropoff_lat = df['dropoff_latitude']\n",
    "    pickup_lon = df['pickup_longitude']\n",
    "    dropoff_lon = df['dropoff_longitude']\n",
    "    \n",
    "    pickup_jfk = havesine_distance_and_bearing(pickup_lat, pickup_lon, jfk_coord[0], jfk_coord[1],False) \n",
    "    dropoff_jfk = havesine_distance_and_bearing(jfk_coord[0], jfk_coord[1], dropoff_lat, dropoff_lon,False) \n",
    "    pickup_ewr = havesine_distance_and_bearing(pickup_lat, pickup_lon, ewr_coord[0], ewr_coord[1],False)\n",
    "    dropoff_ewr = havesine_distance_and_bearing(ewr_coord[0], ewr_coord[1], dropoff_lat, dropoff_lon,False) \n",
    "    pickup_lga = havesine_distance_and_bearing(pickup_lat, pickup_lon, lga_coord[0], lga_coord[1],False) \n",
    "    dropoff_lga = havesine_distance_and_bearing(lga_coord[0], lga_coord[1], dropoff_lat, dropoff_lon,False)\n",
    "    pickup_sol = havesine_distance_and_bearing(pickup_lat, pickup_lon, sol_coord[0], sol_coord[1],False) \n",
    "    dropoff_sol = havesine_distance_and_bearing(sol_coord[0], sol_coord[1], dropoff_lat, dropoff_lon,False)\n",
    "    pickup_nyc = havesine_distance_and_bearing(pickup_lat, pickup_lon, nyc_coord[0], nyc_coord[1],False) \n",
    "    dropoff_nyc = havesine_distance_and_bearing(nyc_coord[0], nyc_coord[1], dropoff_lat, dropoff_lon,False)\n",
    "    \n",
    "\n",
    "    df['nyc_dist'] = pickup_nyc + dropoff_nyc\n",
    "    df['jfk_dist'] = pickup_jfk + dropoff_jfk\n",
    "    df['ewr_dist'] = pickup_ewr + dropoff_ewr\n",
    "    df['lga_dist'] = pickup_lga + dropoff_lga\n",
    "    df['sol_dist'] = pickup_sol + dropoff_sol\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for getting Date, Month, Year, Weekday, Hour from date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetimeinfo(df):\n",
    "    #Convert to datetime format\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "    \n",
    "    df['day'] = df.pickup_datetime.dt.day\n",
    "    df['month'] = df.pickup_datetime.dt.month\n",
    "    df['year'] = df.pickup_datetime.dt.year\n",
    "    df['weekday'] = df.pickup_datetime.dt.weekday\n",
    "    df['hour'] = df.pickup_datetime.dt.hour\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply all the above functions to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_datetimeinfo(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove Unwanted Columns\n",
    "train.drop(columns=['key', 'pickup_datetime'], inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'], train['bearing'] = havesine_distance_and_bearing(train['pickup_latitude'], train['pickup_longitude'], train['dropoff_latitude'] , train['dropoff_longitude'],True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_airport_dist(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Table after feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>distance</th>\n",
       "      <th>bearing</th>\n",
       "      <th>nyc_dist</th>\n",
       "      <th>jfk_dist</th>\n",
       "      <th>ewr_dist</th>\n",
       "      <th>lga_dist</th>\n",
       "      <th>sol_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.030764</td>\n",
       "      <td>2.918897</td>\n",
       "      <td>27.572573</td>\n",
       "      <td>20.265840</td>\n",
       "      <td>55.176046</td>\n",
       "      <td>14.342611</td>\n",
       "      <td>34.543548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>8.450134</td>\n",
       "      <td>0.375217</td>\n",
       "      <td>8.755732</td>\n",
       "      <td>44.667679</td>\n",
       "      <td>31.832358</td>\n",
       "      <td>23.130775</td>\n",
       "      <td>15.125872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.389525</td>\n",
       "      <td>-2.599961</td>\n",
       "      <td>9.847344</td>\n",
       "      <td>43.597686</td>\n",
       "      <td>33.712082</td>\n",
       "      <td>19.865289</td>\n",
       "      <td>17.722624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.799270</td>\n",
       "      <td>-0.133905</td>\n",
       "      <td>7.703421</td>\n",
       "      <td>42.642965</td>\n",
       "      <td>32.556289</td>\n",
       "      <td>21.063132</td>\n",
       "      <td>15.738963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.999157</td>\n",
       "      <td>0.502703</td>\n",
       "      <td>15.600745</td>\n",
       "      <td>43.329953</td>\n",
       "      <td>39.406828</td>\n",
       "      <td>15.219339</td>\n",
       "      <td>23.732406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          4.5        -73.844311        40.721319         -73.841610   \n",
       "1         16.9        -74.016048        40.711303         -73.979268   \n",
       "2          5.7        -73.982738        40.761270         -73.991242   \n",
       "3          7.7        -73.987130        40.733143         -73.991567   \n",
       "4          5.3        -73.968095        40.768008         -73.956655   \n",
       "\n",
       "   dropoff_latitude  passenger_count  day  month  year  weekday  hour  \\\n",
       "0         40.712278                1   15      6  2009        0    17   \n",
       "1         40.782004                1    5      1  2010        1    16   \n",
       "2         40.750562                2   18      8  2011        3     0   \n",
       "3         40.758092                1   21      4  2012        5     4   \n",
       "4         40.783762                1    9      3  2010        1     7   \n",
       "\n",
       "   distance   bearing   nyc_dist   jfk_dist   ewr_dist   lga_dist   sol_dist  \n",
       "0  1.030764  2.918897  27.572573  20.265840  55.176046  14.342611  34.543548  \n",
       "1  8.450134  0.375217   8.755732  44.667679  31.832358  23.130775  15.125872  \n",
       "2  1.389525 -2.599961   9.847344  43.597686  33.712082  19.865289  17.722624  \n",
       "3  2.799270 -0.133905   7.703421  42.642965  32.556289  21.063132  15.738963  \n",
       "4  1.999157  0.502703  15.600745  43.329953  39.406828  15.219339  23.732406  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Target Variable in seperate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['fare_amount']\n",
    "train = train.drop(columns=['fare_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,valid,y,y_valid = train_test_split(train,y,random_state=123,test_size=0.09)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply LightGBM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\tvalid_0's rmse: 3.57317\n",
      "[1000]\tvalid_0's rmse: 3.51153\n",
      "[1500]\tvalid_0's rmse: 3.48382\n",
      "[2000]\tvalid_0's rmse: 3.46569\n",
      "[2500]\tvalid_0's rmse: 3.45255\n",
      "[3000]\tvalid_0's rmse: 3.44425\n",
      "[3500]\tvalid_0's rmse: 3.43776\n",
      "[4000]\tvalid_0's rmse: 3.43124\n",
      "[4500]\tvalid_0's rmse: 3.42686\n",
      "[5000]\tvalid_0's rmse: 3.42277\n",
      "[5500]\tvalid_0's rmse: 3.4193\n",
      "[6000]\tvalid_0's rmse: 3.41521\n",
      "[6500]\tvalid_0's rmse: 3.41159\n",
      "[7000]\tvalid_0's rmse: 3.4093\n",
      "[7500]\tvalid_0's rmse: 3.40688\n",
      "[8000]\tvalid_0's rmse: 3.40471\n",
      "[8500]\tvalid_0's rmse: 3.40312\n",
      "[9000]\tvalid_0's rmse: 3.40108\n",
      "[9500]\tvalid_0's rmse: 3.3996\n",
      "[10000]\tvalid_0's rmse: 3.39767\n",
      "[10500]\tvalid_0's rmse: 3.39613\n",
      "[11000]\tvalid_0's rmse: 3.39502\n",
      "[11500]\tvalid_0's rmse: 3.39379\n",
      "[12000]\tvalid_0's rmse: 3.39289\n",
      "[12500]\tvalid_0's rmse: 3.39165\n",
      "[13000]\tvalid_0's rmse: 3.39086\n",
      "[13500]\tvalid_0's rmse: 3.38982\n",
      "[14000]\tvalid_0's rmse: 3.38917\n",
      "[14500]\tvalid_0's rmse: 3.38797\n",
      "[15000]\tvalid_0's rmse: 3.38728\n",
      "[15500]\tvalid_0's rmse: 3.38645\n",
      "[16000]\tvalid_0's rmse: 3.38592\n",
      "[16500]\tvalid_0's rmse: 3.3852\n",
      "[17000]\tvalid_0's rmse: 3.3847\n",
      "[17500]\tvalid_0's rmse: 3.38402\n",
      "[18000]\tvalid_0's rmse: 3.38358\n",
      "[18500]\tvalid_0's rmse: 3.38304\n",
      "[19000]\tvalid_0's rmse: 3.38245\n",
      "[19500]\tvalid_0's rmse: 3.3821\n",
      "[20000]\tvalid_0's rmse: 3.38183\n",
      "[20500]\tvalid_0's rmse: 3.38135\n",
      "[21000]\tvalid_0's rmse: 3.3808\n",
      "[21500]\tvalid_0's rmse: 3.38047\n",
      "[22000]\tvalid_0's rmse: 3.38008\n",
      "[22500]\tvalid_0's rmse: 3.37977\n",
      "[23000]\tvalid_0's rmse: 3.37944\n",
      "[23500]\tvalid_0's rmse: 3.37917\n",
      "[24000]\tvalid_0's rmse: 3.37886\n",
      "[24500]\tvalid_0's rmse: 3.37867\n",
      "[25000]\tvalid_0's rmse: 3.37848\n",
      "[25500]\tvalid_0's rmse: 3.37821\n",
      "[26000]\tvalid_0's rmse: 3.37797\n",
      "[26500]\tvalid_0's rmse: 3.37767\n",
      "[27000]\tvalid_0's rmse: 3.37719\n",
      "[27500]\tvalid_0's rmse: 3.37706\n",
      "[28000]\tvalid_0's rmse: 3.3769\n",
      "[28500]\tvalid_0's rmse: 3.37666\n",
      "[29000]\tvalid_0's rmse: 3.37653\n",
      "[29500]\tvalid_0's rmse: 3.37627\n",
      "[30000]\tvalid_0's rmse: 3.376\n",
      "[30500]\tvalid_0's rmse: 3.37589\n",
      "[31000]\tvalid_0's rmse: 3.3757\n",
      "[31500]\tvalid_0's rmse: 3.3756\n",
      "[32000]\tvalid_0's rmse: 3.37553\n",
      "[32500]\tvalid_0's rmse: 3.37536\n",
      "[33000]\tvalid_0's rmse: 3.37526\n",
      "[33500]\tvalid_0's rmse: 3.375\n",
      "[34000]\tvalid_0's rmse: 3.37471\n",
      "[34500]\tvalid_0's rmse: 3.37446\n",
      "[35000]\tvalid_0's rmse: 3.37416\n",
      "[35500]\tvalid_0's rmse: 3.37407\n",
      "[36000]\tvalid_0's rmse: 3.37392\n",
      "[36500]\tvalid_0's rmse: 3.37382\n",
      "[37000]\tvalid_0's rmse: 3.3738\n",
      "[37500]\tvalid_0's rmse: 3.37346\n",
      "[38000]\tvalid_0's rmse: 3.37319\n",
      "[38500]\tvalid_0's rmse: 3.37304\n",
      "[39000]\tvalid_0's rmse: 3.37291\n",
      "[39500]\tvalid_0's rmse: 3.37275\n",
      "[40000]\tvalid_0's rmse: 3.37266\n",
      "[40500]\tvalid_0's rmse: 3.37235\n",
      "[41000]\tvalid_0's rmse: 3.37217\n",
      "[41500]\tvalid_0's rmse: 3.37211\n",
      "[42000]\tvalid_0's rmse: 3.37199\n",
      "[42500]\tvalid_0's rmse: 3.37178\n",
      "[43000]\tvalid_0's rmse: 3.37169\n",
      "Early stopping, best iteration is:\n",
      "[42852]\tvalid_0's rmse: 3.37165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': 4,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "        'bagging_fraction' : 1,\n",
    "        'max_bin' : 4000 ,\n",
    "        'bagging_freq': 20,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1,\n",
    "        'zero_as_missing': True,\n",
    "        'seed':0,\n",
    "        'num_rounds':50000\n",
    "    }\n",
    "    \n",
    "train = lgbm.Dataset(train, y,categorical_feature=['year','month','day','weekday'])\n",
    "valid = lgbm.Dataset(valid, y_valid,categorical_feature=['year','month','day','weekday'])\n",
    "model = lgbm.train(params, train_set = train, num_boost_round=10000,early_stopping_rounds=500,verbose_eval=500, valid_sets=valid)\n",
    "del train\n",
    "del y\n",
    "del valid\n",
    "del y_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Test.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Feature Engineering on Test.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_datetimeinfo(test)\n",
    "test['distance'], test['bearing'] = havesine_distance_and_bearing(test['pickup_latitude'], test['pickup_longitude'], test['dropoff_latitude'] , test['dropoff_longitude'],True) \n",
    "test = add_airport_dist(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Unwanted Columns\n",
    "test_key = test['key']\n",
    "test.drop(columns=['key', 'pickup_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['fare_amount'] = model.predict(test, num_iteration = model.best_iteration)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save CSV File, so we can submit it to competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['key'] = test_key\n",
    "test[['key','fare_amount']].to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
